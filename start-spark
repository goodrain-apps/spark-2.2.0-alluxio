#!/usr/bin/env bash

# Set default HDFS user if not set
if [[ -z "${HDFS_USER}" ]]; then
  export HDFS_USER=spark
fi
if [[ "${DEBUG}" ]];then
  echo "debug is true ,will sleep ${DEBUG} seconds"
  sleep ${DEBUG}
fi  
if [[ "${1}" = 'master' ]]; then
  # Start Spark Master
  exec spark-class org.apache.spark.deploy.master.Master -h $(hostname)
elif [[ "${1}" = 'worker' ]]; then
  # Start Spark Worker
  exec spark-class org.apache.spark.deploy.worker.Worker spark://$2
else
  if [[ "${RUN_MODE}" == 'master' ]];then
     # Start Spark Master
     exec spark-class org.apache.spark.deploy.master.Master -h $(hostname)
  elif [[ "${RUN_MODE}" = 'worker' ]]; then
     # Start Spark Worker
     exec spark-class org.apache.spark.deploy.worker.Worker spark://${SPARK_MASTER_HOST}:${SPARK_MASTER_PORT}
  else   
     echo "Invalid command '${1}'" >&2
     exit 1
  fi   
fi
